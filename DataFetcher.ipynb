{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335e9f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run this cell first if packages are not installed)\n",
    "!pip install --user pandas gspread gspread-dataframe google-auth google-auth-oauthlib google-auth-httplib2\n",
    "\n",
    "print(\"‚úÖ All dependencies installed successfully!\")\n",
    "print(\"   You can now run the main code cell below.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6bde52",
   "metadata": {},
   "source": [
    "# üìä Metabase to Google Sheets - Data Fetcher\n",
    "\n",
    "**Self-contained notebook - Duplicate this file for each new sheet you want to create**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Configuration\n",
    "\n",
    "Edit the cell below to customize your data fetch:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a641943",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è IMPORTANT: Google Sheets Limitations\n",
    "\n",
    "**Google Sheets has a hard limit of 10 million cells per spreadsheet.**\n",
    "\n",
    "Your current dataset: **2,004,530 rows √ó 17 columns = 34,077,112 cells**\n",
    "\n",
    "This exceeds the limit by **3.4x**! Choose one solution below:\n",
    "\n",
    "### üî• **Solution 1: Split into Multiple Sheets (Recommended)**\n",
    "Split data by date ranges or categories into separate sheets within the same spreadsheet.\n",
    "\n",
    "### üìä **Solution 2: Use Multiple Spreadsheets**\n",
    "Create separate spreadsheets for different time periods or data segments.\n",
    "\n",
    "### üóúÔ∏è **Solution 3: Reduce Data Size**\n",
    "Filter data to only what's needed, or aggregate before uploading.\n",
    "\n",
    "### üíæ **Solution 4: Use BigQuery or Database** \n",
    "For large datasets, consider using BigQuery directly instead of Google Sheets.\n",
    "\n",
    "---\n",
    "\n",
    "**Run the appropriate cell below based on your choice:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8874f2d3",
   "metadata": {},
   "source": [
    "### üî• SOLUTION 1: Split by Date Range (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcff18d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION 1: Split Data by Month into Separate Sheets\n",
    "# This uploads data in monthly chunks to different sheets in the SAME spreadsheet\n",
    "\n",
    "import pandas as pd\n",
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "from google.oauth2.service_account import Credentials\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Configuration\n",
    "SPREADSHEET_ID = \"14XMNROBL6PT_GYq43AVJb9e_IowOZp_ZP_IpCwmQCgs\"\n",
    "SERVICE_ACCOUNT_FILE = \"pw-service-22bdcc39f732.json\"\n",
    "DATE_COLUMN = \"converteddate\"  # Column to split by\n",
    "\n",
    "# Add Trino utilities\n",
    "sys.path.append('/home/jovyan/shared/python_utils/')\n",
    "from python_utils_common import trino_prod\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä SPLIT UPLOAD TO GOOGLE SHEETS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Your SQL Query (same as before)\n",
    "SQL_QUERY = \"\"\"\n",
    "WITH main AS (\n",
    "    SELECT *,\n",
    "        COALESCE(NULLIF(TRIM(financeexamcategory), ''), exam) AS final_exam_category\n",
    "    FROM cdp.mview.gold_dbt_orders_base_fact\n",
    "),\n",
    "pw_store_order_cte AS (\n",
    "    SELECT\n",
    "        batch_order_id AS ecom_id,\n",
    "        SUM(net_price) AS add_on_store\n",
    "    FROM cdp.mview.gold_pw_store_orders\n",
    "    WHERE batch_order_id IS NOT NULL\n",
    "    GROUP BY batch_order_id\n",
    "),\n",
    "plans AS (SELECT \n",
    "    batchid,\n",
    "    name,\n",
    "    startdate,\n",
    "    CASE \n",
    "        WHEN pro_plan IS NOT NULL AND infinity_plan IS NOT NULL THEN 'Infinity_Pro_eligible'\n",
    "        WHEN pro_plan IS NOT NULL AND infinity_plan IS NULL AND base_plan IS NULL THEN 'Only_pro_eligible'\n",
    "        WHEN pro_plan IS NULL AND infinity_plan IS NOT NULL THEN 'Only_infinity_eligible'\n",
    "        WHEN pro_plan IS NOT NULL AND infinity_plan IS NULL AND base_plan IS NOT NULL THEN 'base_pro_eligible'\n",
    "        WHEN base_plan IS NOT NULL AND infinity_plan IS NULL AND pro_plan IS NULL THEN 'Only_base_batch'\n",
    "        ELSE 'TBA'\n",
    "    END AS batch_eligibility\n",
    "FROM (\n",
    "    SELECT \n",
    "        name,\n",
    "        batchid,\n",
    "        startdate,\n",
    "        MAX(CASE WHEN displayorder = 1 AND type = 'BATCH' THEN _id END) AS base_plan,\n",
    "        MAX(CASE WHEN type = 'INFINITY' THEN _id END) AS infinity_plan,\n",
    "        MAX(CASE WHEN type = 'PRO' THEN _id END) AS pro_plan\n",
    "    FROM (\n",
    "        SELECT \n",
    "            b.exam,\n",
    "            b.name,\n",
    "            cast(b.startdate as date) as startdate,\n",
    "            batchid,\n",
    "            businessoffering,\n",
    "            a.displayorder,\n",
    "            a._id,\n",
    "            CASE \n",
    "                WHEN lower(businessoffering) LIKE '%pro%' THEN 'PRO'\n",
    "                WHEN lower(businessoffering) LIKE '%infinity%' THEN 'INFINITY'\n",
    "                WHEN businessoffering = ''  THEN 'BATCH'\n",
    "                ELSE 'BATCH'\n",
    "            END AS type\n",
    "        FROM cdp.cdp_revenue.gold_batch_plans a\n",
    "        JOIN cdp.cdp_revenue.gold_batches_pw b\n",
    "            ON a.batchid = b._id\n",
    "        WHERE a.status = 'Active'\n",
    "    ) inner_query\n",
    "    GROUP BY 1, 2 ,3)),\n",
    "filtration as (    \n",
    "SELECT \n",
    "    m._id,\n",
    "    m.batchid,\n",
    "    m.plan,\n",
    "    m.converteddate,\n",
    "    m.name,\n",
    "    m.net_amount,\n",
    "    m.coupondiscount,\n",
    "    m.couponcode,\n",
    "    m.couponid,\n",
    "    m.donationamount,\n",
    "    m.Exam_2,\n",
    "    m.order_type,\n",
    "    p.batch_eligibility,\n",
    "    p.startdate,\n",
    "    s.ADD_ON_STORE,\n",
    "    CASE \n",
    "    WHEN m.Exam_2 IN (\n",
    "        'COMMERCE', 'CA', 'MBA', 'CLAT', 'IIT JAM', 'UGC NET', 'CS', 'CSIR NET',\n",
    "        'Nursing Exams', 'IPMAT', 'CUET PG', 'Pharma', 'Design_Wallah', 'IELTS',\n",
    "        'CA Final', 'ACCA', 'NEET_PG', 'CA Offline', 'MBA_GMAT', 'BFSI'\n",
    "    ) THEN 'MANISH'\n",
    "    \n",
    "    WHEN m.Exam_2 IN (\n",
    "        'SSC', 'Banking', 'WBPSC', 'TET', 'JAIIB AND CAIIB', 'State Exams'\n",
    "    ) THEN 'PRASHANT'\n",
    "    \n",
    "    WHEN m.Exam_2 IN (\n",
    "        'UPSC', 'BPSC', 'UPPSC', 'MPSC', 'Agriculture', 'MPPSC',\n",
    "        'Judiciary', 'GATE', 'AE/JE', 'OPSC'\n",
    "    ) THEN 'RAJAT'\n",
    "    \n",
    "    WHEN m.Exam_2 IN (\n",
    "        'IIT-JEE', 'NEET', 'Foundation', 'Pre_Foundation', 'STATE BOARDS',\n",
    "        'Defence', 'Vernacular', 'CUET UG', 'Bharat Batch'\n",
    "    ) THEN 'SANYAM'\n",
    "    \n",
    "    WHEN m.Exam_2 IN ('Power Batch') THEN 'ANKIT'\n",
    "    \n",
    "    ELSE 'TBA'\n",
    "END AS leader_fin\n",
    "    \n",
    "FROM (\n",
    "    SELECT\n",
    "        orderid AS _id,\n",
    "        productid AS batchid,\n",
    "        businessoffering AS plan,\n",
    "        CAST(order_time AS DATE) AS converteddate,\n",
    "        product_name AS name,\n",
    "        order_price AS net_amount,\n",
    "        order_coupondiscount AS coupondiscount,\n",
    "        coupon_code AS couponcode,\n",
    "        couponid,\n",
    "        order_donationamount AS donationamount,\n",
    "        CASE\n",
    "            WHEN final_exam_category LIKE '%Vernacular%' THEN 'Vernacular'\n",
    "            WHEN final_exam_category IN ('Bihar Exams', 'UP Exams', 'WB Exams') THEN 'State Exams'\n",
    "            WHEN final_exam_category IN ('State PSC - WBPSC') THEN 'WBPSC'\n",
    "            WHEN final_exam_category = 'Board_Exam'\n",
    "                OR final_exam_category LIKE '%State%Board%' THEN 'STATE BOARDS'\n",
    "            WHEN final_exam_category IN ('CUET Arts', 'CUET Science') THEN 'CUET UG'\n",
    "            WHEN final_exam_category IN ('Commerce', 'CUET Commerce') THEN 'COMMERCE'\n",
    "            WHEN final_exam_category IN ('ARCHITECTURE', 'Architecture', 'Design Wallah') THEN 'Design_Wallah'\n",
    "            WHEN final_exam_category = 'State PSC - BPSC' THEN 'BPSC'\n",
    "            WHEN final_exam_category = 'ESE' THEN 'GATE'\n",
    "            WHEN final_exam_category = 'GMAT' THEN 'MBA_GMAT'\n",
    "            WHEN final_exam_category = 'State PSC - MPPSC' THEN 'MPPSC'\n",
    "            WHEN final_exam_category = 'State PSC - MPSC' THEN 'MPSC'\n",
    "            WHEN final_exam_category = 'Nursing' THEN 'Nursing Exams'\n",
    "            WHEN final_exam_category = 'State PSC - OPSC' THEN 'OPSC'\n",
    "            WHEN final_exam_category = 'Railway' THEN 'SSC'\n",
    "            WHEN final_exam_category = 'Teaching' THEN 'TET'\n",
    "            WHEN final_exam_category = 'State PSC - UPPSC' THEN 'UPPSC'\n",
    "            WHEN LOWER(final_exam_category) = 'foundation' THEN 'Foundation'\n",
    "            WHEN final_exam_category IN ('Pre_Foundation', 'PRE_FOUNDATION') THEN 'Pre_Foundation'\n",
    "            ELSE final_exam_category\n",
    "        END AS exam_2,\n",
    "        CASE \n",
    "            WHEN upgradedfrom IS NOT NULL THEN 'UPGRADE' \n",
    "            ELSE 'PRIMARY' \n",
    "        END AS order_type\n",
    "    FROM main\n",
    "    WHERE \n",
    "        isattribution = FALSE\n",
    "        AND isprimary = TRUE\n",
    "        AND issat = FALSE\n",
    "        AND isvidyapeeth = FALSE\n",
    "        AND ispathshala = FALSE\n",
    "        AND (organizationid IN ('5eb393ee95fab7468a79d189', '63b52963e72e8b00186c11f3'))\n",
    "        AND order_price > 0\n",
    "        AND (type = 'BATCH' OR type = 'COMBO_PACKAGE')\n",
    "        AND CAST(\n",
    "                date_add('minute', 330, CAST(order_time AS timestamp))\n",
    "            AS date\n",
    "        ) BETWEEN DATE '2025-02-28' AND DATE '2025-11-06'\n",
    ") m\n",
    "LEFT JOIN pw_store_order_cte s\n",
    "    ON m._id = s.ecom_id\n",
    "LEFT JOIN plans p\n",
    "    ON m.batchid = p.batchid)\n",
    "SELECT *,\n",
    "CASE \n",
    "    WHEN LOWER(plan) LIKE '%pro%' \n",
    "         AND Leader_FIN IN ('SANYAM', 'PRASHANT', 'MANISH', 'RAJAT') \n",
    "        THEN 'PRO'\n",
    "        \n",
    "    WHEN LOWER(plan) LIKE '%infinity%'\n",
    "        THEN 'INFINITY'\n",
    "        \n",
    "    WHEN plan = '' \n",
    "        THEN 'BATCH'\n",
    "        \n",
    "    ELSE 'BATCH'\n",
    "END AS type_2\n",
    "FROM filtration\n",
    "WHERE leader_fin = 'SANYAM'\n",
    "AND Exam_2 IN ('IIT-JEE','NEET','Foundation','CUET UG')\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Fetch data\n",
    "print(\"\\nüîÑ Fetching data from database...\")\n",
    "start_time = time.time()\n",
    "df = trino_prod(SQL_QUERY)\n",
    "print(f\"‚úÖ Fetched {len(df):,} rows in {time.time() - start_time:.2f}s\")\n",
    "\n",
    "# Step 2: Convert date column to datetime\n",
    "df[DATE_COLUMN] = pd.to_datetime(df[DATE_COLUMN])\n",
    "\n",
    "# Step 3: Split by month\n",
    "df['year_month'] = df[DATE_COLUMN].dt.to_period('M')\n",
    "grouped = df.groupby('year_month')\n",
    "\n",
    "print(f\"\\nüìä Data will be split into {len(grouped)} monthly sheets:\")\n",
    "for period, group_df in grouped:\n",
    "    cells = len(group_df) * len(group_df.columns)\n",
    "    print(f\"   - {period}: {len(group_df):,} rows = {cells:,} cells\")\n",
    "\n",
    "# Step 4: Upload each month to a separate sheet\n",
    "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n",
    "creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=scope)\n",
    "client = gspread.authorize(creds)\n",
    "spreadsheet = client.open_by_key(SPREADSHEET_ID)\n",
    "\n",
    "print(f\"\\n‚ö° Uploading to Google Sheets...\")\n",
    "total_uploaded = 0\n",
    "\n",
    "for period, group_df in grouped:\n",
    "    sheet_name = f\"Batch_{period}\"\n",
    "    \n",
    "    # Remove the temporary year_month column\n",
    "    upload_df = group_df.drop('year_month', axis=1)\n",
    "    \n",
    "    rows = len(upload_df)\n",
    "    cols = len(upload_df.columns)\n",
    "    cells = (rows + 6) * cols  # +6 for metadata\n",
    "    \n",
    "    print(f\"\\n   üìÑ Sheet: {sheet_name}\")\n",
    "    print(f\"      Rows: {rows:,} | Cells: {cells:,}\")\n",
    "    \n",
    "    # Create or get worksheet\n",
    "    try:\n",
    "        worksheet = spreadsheet.worksheet(sheet_name)\n",
    "        print(f\"      ‚úì Using existing sheet\")\n",
    "    except:\n",
    "        worksheet = spreadsheet.add_worksheet(title=sheet_name, rows=rows+10, cols=cols)\n",
    "        print(f\"      ‚úì Created new sheet\")\n",
    "    \n",
    "    # Resize if needed\n",
    "    if worksheet.row_count < rows + 10:\n",
    "        worksheet.resize(rows=rows + 10, cols=cols)\n",
    "    \n",
    "    worksheet.clear()\n",
    "    \n",
    "    # Add metadata\n",
    "    metadata = [\n",
    "        [\"Batch Enrollment Report\"],\n",
    "        [f\"Period: {period}\"],\n",
    "        [f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"],\n",
    "        [f\"Records: {rows:,}\"],\n",
    "        []\n",
    "    ]\n",
    "    worksheet.update('A1:A5', metadata, value_input_option='RAW')\n",
    "    \n",
    "    # Upload data\n",
    "    set_with_dataframe(worksheet, upload_df, row=6, include_index=False, include_column_header=True, resize=False)\n",
    "    \n",
    "    # Format header\n",
    "    worksheet.format('A6:Q6', {\n",
    "        \"textFormat\": {\"bold\": True},\n",
    "        \"backgroundColor\": {\"red\": 0.2, \"green\": 0.5, \"blue\": 0.8}\n",
    "    })\n",
    "    \n",
    "    total_uploaded += rows\n",
    "    print(f\"      ‚úÖ Uploaded ({total_uploaded:,} / {len(df):,} total)\")\n",
    "    time.sleep(1)  # Rate limiting\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(f\"‚úÖ SUCCESS! Uploaded {total_uploaded:,} rows across {len(grouped)} sheets\")\n",
    "print(f\"üìä View: https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/edit\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d2b1f",
   "metadata": {},
   "source": [
    "### üóúÔ∏è SOLUTION 2: Aggregate Data (Reduce Rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46caa40",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'python_utils_common'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m SERVICE_ACCOUNT_FILE = \u001b[33m\"\u001b[39m\u001b[33mpw-service-22bdcc39f732.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m sys.path.append(\u001b[33m'\u001b[39m\u001b[33m/home/jovyan/shared/python_utils/\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpython_utils_common\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m trino_prod\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müìä AGGREGATED UPLOAD TO GOOGLE SHEETS\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'python_utils_common'"
     ]
    }
   ],
   "source": [
    "# SOLUTION 2: Upload Only Aggregated Summary Data\n",
    "# This reduces 2M rows to ~1000 rows by aggregating\n",
    "\n",
    "import pandas as pd\n",
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "from google.oauth2.service_account import Credentials\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Configuration\n",
    "SPREADSHEET_ID = \"14XMNROBL6PT_GYq43AVJb9e_IowOZp_ZP_IpCwmQCgs\"\n",
    "WORKSHEET_NAME = \"Batch_Enrollment_Summary\"\n",
    "SERVICE_ACCOUNT_FILE = \"pw-service-22bdcc39f732.json\"\n",
    "\n",
    "sys.path.append('/home/jovyan/shared/python_utils/')\n",
    "from python_utils_common import trino_prod\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä AGGREGATED UPLOAD TO GOOGLE SHEETS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Your SQL Query with aggregation - FIXED\n",
    "SQL_QUERY_AGGREGATED = \"\"\"\n",
    "WITH main AS (\n",
    "    SELECT *,\n",
    "        COALESCE(NULLIF(TRIM(financeexamcategory), ''), exam) AS final_exam_category\n",
    "    FROM cdp.mview.gold_dbt_orders_base_fact\n",
    "),\n",
    "pw_store_order_cte AS (\n",
    "    SELECT\n",
    "        batch_order_id AS ecom_id,\n",
    "        SUM(net_price) AS add_on_store\n",
    "    FROM cdp.mview.gold_pw_store_orders\n",
    "    WHERE batch_order_id IS NOT NULL\n",
    "    GROUP BY batch_order_id\n",
    "),\n",
    "plans AS (\n",
    "    SELECT \n",
    "        batchid,\n",
    "        name,\n",
    "        startdate,\n",
    "        CASE \n",
    "            WHEN pro_plan IS NOT NULL AND infinity_plan IS NOT NULL THEN 'Infinity_Pro_eligible'\n",
    "            WHEN pro_plan IS NOT NULL AND infinity_plan IS NULL AND base_plan IS NULL THEN 'Only_pro_eligible'\n",
    "            WHEN pro_plan IS NULL AND infinity_plan IS NOT NULL THEN 'Only_infinity_eligible'\n",
    "            WHEN pro_plan IS NOT NULL AND infinity_plan IS NULL AND base_plan IS NOT NULL THEN 'base_pro_eligible'\n",
    "            WHEN base_plan IS NOT NULL AND infinity_plan IS NULL AND pro_plan IS NULL THEN 'Only_base_batch'\n",
    "            ELSE 'TBA'\n",
    "        END AS batch_eligibility\n",
    "    FROM (\n",
    "        SELECT \n",
    "            name,\n",
    "            batchid,\n",
    "            startdate,\n",
    "            MAX(CASE WHEN displayorder = 1 AND type = 'BATCH' THEN _id END) AS base_plan,\n",
    "            MAX(CASE WHEN type = 'INFINITY' THEN _id END) AS infinity_plan,\n",
    "            MAX(CASE WHEN type = 'PRO' THEN _id END) AS pro_plan\n",
    "        FROM (\n",
    "            SELECT \n",
    "                b.exam,\n",
    "                b.name,\n",
    "                cast(b.startdate as date) as startdate,\n",
    "                batchid,\n",
    "                businessoffering,\n",
    "                a.displayorder,\n",
    "                a._id,\n",
    "                CASE \n",
    "                    WHEN lower(businessoffering) LIKE '%pro%' THEN 'PRO'\n",
    "                    WHEN lower(businessoffering) LIKE '%infinity%' THEN 'INFINITY'\n",
    "                    WHEN businessoffering = '' THEN 'BATCH'\n",
    "                    ELSE 'BATCH'\n",
    "                END AS type\n",
    "            FROM cdp.cdp_revenue.gold_batch_plans a\n",
    "            JOIN cdp.cdp_revenue.gold_batches_pw b ON a.batchid = b._id\n",
    "            WHERE a.status = 'Active'\n",
    "        ) inner_query\n",
    "        GROUP BY 1, 2, 3\n",
    "    )\n",
    "),\n",
    "base_data AS (\n",
    "    SELECT\n",
    "        productid AS batchid,\n",
    "        businessoffering AS plan,\n",
    "        CAST(order_time AS DATE) AS converteddate,\n",
    "        product_name AS name,\n",
    "        order_price AS net_amount,\n",
    "        order_coupondiscount AS coupondiscount,\n",
    "        order_donationamount AS donationamount,\n",
    "        orderid,\n",
    "        upgradedfrom,\n",
    "        CASE\n",
    "            WHEN final_exam_category LIKE '%Vernacular%' THEN 'Vernacular'\n",
    "            WHEN final_exam_category IN ('Bihar Exams', 'UP Exams', 'WB Exams') THEN 'State Exams'\n",
    "            WHEN final_exam_category IN ('State PSC - WBPSC') THEN 'WBPSC'\n",
    "            WHEN final_exam_category = 'Board_Exam' OR final_exam_category LIKE '%State%Board%' THEN 'STATE BOARDS'\n",
    "            WHEN final_exam_category IN ('CUET Arts', 'CUET Science') THEN 'CUET UG'\n",
    "            WHEN final_exam_category IN ('Commerce', 'CUET Commerce') THEN 'COMMERCE'\n",
    "            WHEN final_exam_category IN ('ARCHITECTURE', 'Architecture', 'Design Wallah') THEN 'Design_Wallah'\n",
    "            WHEN final_exam_category = 'State PSC - BPSC' THEN 'BPSC'\n",
    "            WHEN final_exam_category = 'ESE' THEN 'GATE'\n",
    "            WHEN final_exam_category = 'GMAT' THEN 'MBA_GMAT'\n",
    "            WHEN final_exam_category = 'State PSC - MPPSC' THEN 'MPPSC'\n",
    "            WHEN final_exam_category = 'State PSC - MPSC' THEN 'MPSC'\n",
    "            WHEN final_exam_category = 'Nursing' THEN 'Nursing Exams'\n",
    "            WHEN final_exam_category = 'State PSC - OPSC' THEN 'OPSC'\n",
    "            WHEN final_exam_category = 'Railway' THEN 'SSC'\n",
    "            WHEN final_exam_category = 'Teaching' THEN 'TET'\n",
    "            WHEN final_exam_category = 'State PSC - UPPSC' THEN 'UPPSC'\n",
    "            WHEN LOWER(final_exam_category) = 'foundation' THEN 'Foundation'\n",
    "            WHEN final_exam_category IN ('Pre_Foundation', 'PRE_FOUNDATION') THEN 'Pre_Foundation'\n",
    "            ELSE final_exam_category\n",
    "        END AS exam_2\n",
    "    FROM main\n",
    "    WHERE \n",
    "        isattribution = FALSE\n",
    "        AND isprimary = TRUE\n",
    "        AND issat = FALSE\n",
    "        AND isvidyapeeth = FALSE\n",
    "        AND ispathshala = FALSE\n",
    "        AND (organizationid IN ('5eb393ee95fab7468a79d189', '63b52963e72e8b00186c11f3'))\n",
    "        AND order_price > 0\n",
    "        AND (type = 'BATCH' OR type = 'COMBO_PACKAGE')\n",
    "        AND CAST(date_add('minute', 330, CAST(order_time AS timestamp)) AS date) \n",
    "            BETWEEN DATE '2025-02-28' AND DATE '2025-11-06'\n",
    "),\n",
    "filtration AS (    \n",
    "    SELECT \n",
    "        bd.converteddate,\n",
    "        bd.name,\n",
    "        bd.exam_2,\n",
    "        CASE \n",
    "            WHEN bd.upgradedfrom IS NOT NULL THEN 'UPGRADE' \n",
    "            ELSE 'PRIMARY' \n",
    "        END AS order_type,\n",
    "        p.batch_eligibility,\n",
    "        CASE \n",
    "            WHEN LOWER(bd.plan) LIKE '%pro%' \n",
    "                 AND bd.exam_2 IN ('IIT-JEE', 'NEET', 'Foundation', 'Pre_Foundation', 'STATE BOARDS', 'Defence', 'Vernacular', 'CUET UG', 'Bharat Batch')\n",
    "                THEN 'PRO'\n",
    "            WHEN LOWER(bd.plan) LIKE '%infinity%'\n",
    "                THEN 'INFINITY'\n",
    "            WHEN bd.plan = '' \n",
    "                THEN 'BATCH'\n",
    "            ELSE 'BATCH'\n",
    "        END AS type_2,\n",
    "        bd.net_amount,\n",
    "        bd.coupondiscount,\n",
    "        bd.donationamount,\n",
    "        s.ADD_ON_STORE,\n",
    "        CASE \n",
    "            WHEN bd.exam_2 IN ('COMMERCE', 'CA', 'MBA', 'CLAT', 'IIT JAM', 'UGC NET', 'CS', 'CSIR NET', 'Nursing Exams', 'IPMAT', 'CUET PG', 'Pharma', 'Design_Wallah', 'IELTS', 'CA Final', 'ACCA', 'NEET_PG', 'CA Offline', 'MBA_GMAT', 'BFSI') THEN 'MANISH'\n",
    "            WHEN bd.exam_2 IN ('SSC', 'Banking', 'WBPSC', 'TET', 'JAIIB AND CAIIB', 'State Exams') THEN 'PRASHANT'\n",
    "            WHEN bd.exam_2 IN ('UPSC', 'BPSC', 'UPPSC', 'MPSC', 'Agriculture', 'MPPSC', 'Judiciary', 'GATE', 'AE/JE', 'OPSC') THEN 'RAJAT'\n",
    "            WHEN bd.exam_2 IN ('IIT-JEE', 'NEET', 'Foundation', 'Pre_Foundation', 'STATE BOARDS', 'Defence', 'Vernacular', 'CUET UG', 'Bharat Batch') THEN 'SANYAM'\n",
    "            WHEN bd.exam_2 IN ('Power Batch') THEN 'ANKIT'\n",
    "            ELSE 'TBA'\n",
    "        END AS leader_fin\n",
    "    FROM base_data bd\n",
    "    LEFT JOIN pw_store_order_cte s ON bd.orderid = s.ecom_id\n",
    "    LEFT JOIN plans p ON bd.batchid = p.batchid\n",
    "    WHERE \n",
    "        bd.exam_2 IN ('IIT-JEE','NEET','Foundation','CUET UG')\n",
    ")\n",
    "-- AGGREGATION: Group by date, batch, exam, type to reduce rows from 2M to ~thousands\n",
    "SELECT\n",
    "    converteddate,\n",
    "    name AS batch_name,\n",
    "    Exam_2,\n",
    "    order_type,\n",
    "    type_2 AS plan_type,\n",
    "    batch_eligibility,\n",
    "    leader_fin,\n",
    "    COUNT(*) AS total_orders,\n",
    "    SUM(net_amount) AS total_revenue,\n",
    "    SUM(coupondiscount) AS total_discount,\n",
    "    SUM(donationamount) AS total_donation,\n",
    "    SUM(ADD_ON_STORE) AS total_addon_store,\n",
    "    AVG(net_amount) AS avg_order_value\n",
    "FROM filtration\n",
    "WHERE leader_fin = 'SANYAM'\n",
    "GROUP BY 1, 2, 3, 4, 5, 6, 7\n",
    "ORDER BY 1 DESC, 2\n",
    "\"\"\"\n",
    "\n",
    "# Fetch aggregated data\n",
    "print(\"\\nüîÑ Fetching aggregated data...\")\n",
    "start_time = time.time()\n",
    "df = trino_prod(SQL_QUERY_AGGREGATED)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ Fetched {len(df):,} rows (aggregated) in {elapsed:.2f}s\")\n",
    "print(f\"   Cells: {len(df) * len(df.columns):,} (fits easily!)\")\n",
    "\n",
    "# Upload to Google Sheets\n",
    "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n",
    "creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=scope)\n",
    "client = gspread.authorize(creds)\n",
    "spreadsheet = client.open_by_key(SPREADSHEET_ID)\n",
    "\n",
    "try:\n",
    "    worksheet = spreadsheet.worksheet(WORKSHEET_NAME)\n",
    "except:\n",
    "    worksheet = spreadsheet.add_worksheet(title=WORKSHEET_NAME, rows=len(df)+10, cols=len(df.columns))\n",
    "\n",
    "worksheet.resize(rows=len(df)+10, cols=len(df.columns))\n",
    "worksheet.clear()\n",
    "\n",
    "metadata = [\n",
    "    [\"Batch Enrollment Report - Aggregated Summary\"],\n",
    "    [f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"],\n",
    "    [f\"Total Orders: {df['total_orders'].sum():,.0f}\"],\n",
    "    [f\"Aggregated Rows: {len(df):,}\"],\n",
    "    []\n",
    "]\n",
    "worksheet.update('A1:A5', metadata, value_input_option='RAW')\n",
    "\n",
    "set_with_dataframe(worksheet, df, row=6, include_index=False, include_column_header=True, resize=False)\n",
    "\n",
    "print(f\"\\n‚úÖ SUCCESS! Uploaded {len(df):,} aggregated rows\")\n",
    "print(f\"üìä View: https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/edit#gid={worksheet.id}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1549fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available catalogs in Trino (run this once to find your catalog name)\n",
    "import sys\n",
    "sys.path.append('/home/jovyan/shared/python_utils/')\n",
    "from python_utils_common import trino_prod\n",
    "\n",
    "try:\n",
    "    catalogs_df = trino_prod(\"SHOW CATALOGS\")\n",
    "    print(\"Available Catalogs in Trino:\")\n",
    "    print(\"=\" * 50)\n",
    "    display(catalogs_df)\n",
    "    print(\"\\nUse one of these catalog names in your query.\")\n",
    "    print(\"Example: catalog_name.cdp_revenue.gold_batches\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"\\nTrying alternative approach...\")\n",
    "    try:\n",
    "        # Try to get current catalog\n",
    "        session_df = trino_prod(\"SHOW SESSION\")\n",
    "        display(session_df)\n",
    "    except Exception as e2:\n",
    "        print(f\"Error: {e2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0075811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================================================\n",
    "# CONFIGURATION - EDIT THIS SECTION\n",
    "# ========================================================================================================\n",
    "\n",
    "# Google Sheets Settings\n",
    "SPREADSHEET_ID = \"14XMNROBL6PT_GYq43AVJb9e_IowOZp_ZP_IpCwmQCgs\"  # Your Google Sheet ID\n",
    "WORKSHEET_NAME = \"Batch Enrollment\"  # Tab name in Google Sheet\n",
    "SERVICE_ACCOUNT_FILE = \"pw-service-22bdcc39f732.json\"  # Service account JSON file\n",
    "\n",
    "# Advanced Settings\n",
    "AUTO_DELETE_OLD_SHEETS = True  # Automatically delete old sheets if space is needed\n",
    "PROTECT_FIRST_SHEET = False  # Set to False to allow deleting the first sheet if needed for space\n",
    "\n",
    "# Query Settings\n",
    "QUERY_NAME = \"Batch Enrollment Report\"\n",
    "SQL_QUERY = \"\"\"\n",
    "WITH main AS (\n",
    "    SELECT *,\n",
    "        COALESCE(NULLIF(TRIM(financeexamcategory), ''), exam) AS final_exam_category\n",
    "    FROM cdp.mview.gold_dbt_orders_base_fact\n",
    "),\n",
    "pw_store_order_cte AS (\n",
    "    SELECT\n",
    "        batch_order_id AS ecom_id,\n",
    "        SUM(net_price) AS add_on_store\n",
    "    FROM cdp.mview.gold_pw_store_orders\n",
    "    WHERE batch_order_id IS NOT NULL\n",
    "    GROUP BY batch_order_id\n",
    "),\n",
    "plans AS (SELECT \n",
    "    batchid,\n",
    "    name,\n",
    "    startdate,\n",
    "    CASE \n",
    "        WHEN pro_plan IS NOT NULL AND infinity_plan IS NOT NULL THEN 'Infinity_Pro_eligible'\n",
    "        WHEN pro_plan IS NOT NULL AND infinity_plan IS NULL AND base_plan IS NULL THEN 'Only_pro_eligible'\n",
    "        WHEN pro_plan IS NULL AND infinity_plan IS NOT NULL THEN 'Only_infinity_eligible'\n",
    "        WHEN pro_plan IS NOT NULL AND infinity_plan IS NULL AND base_plan IS NOT NULL THEN 'base_pro_eligible'\n",
    "        WHEN base_plan IS NOT NULL AND infinity_plan IS NULL AND pro_plan IS NULL THEN 'Only_base_batch'\n",
    "        ELSE 'TBA'\n",
    "    END AS batch_eligibility\n",
    "FROM (\n",
    "    SELECT \n",
    "        name,\n",
    "        batchid,\n",
    "        startdate,\n",
    "        MAX(CASE WHEN displayorder = 1 AND type = 'BATCH' THEN _id END) AS base_plan,\n",
    "        MAX(CASE WHEN type = 'INFINITY' THEN _id END) AS infinity_plan,\n",
    "        MAX(CASE WHEN type = 'PRO' THEN _id END) AS pro_plan\n",
    "    FROM (\n",
    "        SELECT \n",
    "            b.exam,\n",
    "            b.name,\n",
    "            cast(b.startdate as date) as startdate,\n",
    "            batchid,\n",
    "            businessoffering,\n",
    "            a.displayorder,\n",
    "            a._id,\n",
    "            CASE \n",
    "                WHEN lower(businessoffering) LIKE '%pro%' THEN 'PRO'\n",
    "                WHEN lower(businessoffering) LIKE '%infinity%' THEN 'INFINITY'\n",
    "                WHEN businessoffering = ''  THEN 'BATCH'\n",
    "                ELSE 'BATCH'\n",
    "            END AS type\n",
    "        FROM cdp.cdp_revenue.gold_batch_plans a\n",
    "        JOIN cdp.cdp_revenue.gold_batches_pw b\n",
    "            ON a.batchid = b._id\n",
    "        WHERE a.status = 'Active'\n",
    "    ) inner_query\n",
    "    GROUP BY 1, 2 ,3)),\n",
    "filtration as (    \n",
    "SELECT \n",
    "    m._id,\n",
    "    m.batchid,\n",
    "    m.plan,\n",
    "    m.converteddate,\n",
    "    m.name,\n",
    "    m.net_amount,\n",
    "    m.coupondiscount,\n",
    "    m.couponcode,\n",
    "    m.couponid,\n",
    "    m.donationamount,\n",
    "    m.Exam_2,\n",
    "    m.order_type,\n",
    "    p.batch_eligibility,\n",
    "    p.startdate,\n",
    "    s.ADD_ON_STORE,\n",
    "    CASE \n",
    "    WHEN m.Exam_2 IN (\n",
    "        'COMMERCE', 'CA', 'MBA', 'CLAT', 'IIT JAM', 'UGC NET', 'CS', 'CSIR NET',\n",
    "        'Nursing Exams', 'IPMAT', 'CUET PG', 'Pharma', 'Design_Wallah', 'IELTS',\n",
    "        'CA Final', 'ACCA', 'NEET_PG', 'CA Offline', 'MBA_GMAT', 'BFSI'\n",
    "    ) THEN 'MANISH'\n",
    "    \n",
    "    WHEN m.Exam_2 IN (\n",
    "        'SSC', 'Banking', 'WBPSC', 'TET', 'JAIIB AND CAIIB', 'State Exams'\n",
    "    ) THEN 'PRASHANT'\n",
    "    \n",
    "    WHEN m.Exam_2 IN (\n",
    "        'UPSC', 'BPSC', 'UPPSC', 'MPSC', 'Agriculture', 'MPPSC',\n",
    "        'Judiciary', 'GATE', 'AE/JE', 'OPSC'\n",
    "    ) THEN 'RAJAT'\n",
    "    \n",
    "    WHEN m.Exam_2 IN (\n",
    "        'IIT-JEE', 'NEET', 'Foundation', 'Pre_Foundation', 'STATE BOARDS',\n",
    "        'Defence', 'Vernacular', 'CUET UG', 'Bharat Batch'\n",
    "    ) THEN 'SANYAM'\n",
    "    \n",
    "    WHEN m.Exam_2 IN ('Power Batch') THEN 'ANKIT'\n",
    "    \n",
    "    ELSE 'TBA'\n",
    "END AS leader_fin\n",
    "    \n",
    "FROM (\n",
    "    SELECT\n",
    "        orderid AS _id,\n",
    "        productid AS batchid,\n",
    "        businessoffering AS plan,\n",
    "        CAST(order_time AS DATE) AS converteddate,\n",
    "        product_name AS name,\n",
    "        order_price AS net_amount,\n",
    "        order_coupondiscount AS coupondiscount,\n",
    "        coupon_code AS couponcode,\n",
    "        couponid,\n",
    "        order_donationamount AS donationamount,\n",
    "        CASE\n",
    "            WHEN final_exam_category LIKE '%Vernacular%' THEN 'Vernacular'\n",
    "            WHEN final_exam_category IN ('Bihar Exams', 'UP Exams', 'WB Exams') THEN 'State Exams'\n",
    "            WHEN final_exam_category IN ('State PSC - WBPSC') THEN 'WBPSC'\n",
    "            WHEN final_exam_category = 'Board_Exam'\n",
    "                OR final_exam_category LIKE '%State%Board%' THEN 'STATE BOARDS'\n",
    "            WHEN final_exam_category IN ('CUET Arts', 'CUET Science') THEN 'CUET UG'\n",
    "            WHEN final_exam_category IN ('Commerce', 'CUET Commerce') THEN 'COMMERCE'\n",
    "            WHEN final_exam_category IN ('ARCHITECTURE', 'Architecture', 'Design Wallah') THEN 'Design_Wallah'\n",
    "            WHEN final_exam_category = 'State PSC - BPSC' THEN 'BPSC'\n",
    "            WHEN final_exam_category = 'ESE' THEN 'GATE'\n",
    "            WHEN final_exam_category = 'GMAT' THEN 'MBA_GMAT'\n",
    "            WHEN final_exam_category = 'State PSC - MPPSC' THEN 'MPPSC'\n",
    "            WHEN final_exam_category = 'State PSC - MPSC' THEN 'MPSC'\n",
    "            WHEN final_exam_category = 'Nursing' THEN 'Nursing Exams'\n",
    "            WHEN final_exam_category = 'State PSC - OPSC' THEN 'OPSC'\n",
    "            WHEN final_exam_category = 'Railway' THEN 'SSC'\n",
    "            WHEN final_exam_category = 'Teaching' THEN 'TET'\n",
    "            WHEN final_exam_category = 'State PSC - UPPSC' THEN 'UPPSC'\n",
    "            WHEN LOWER(final_exam_category) = 'foundation' THEN 'Foundation'\n",
    "            WHEN final_exam_category IN ('Pre_Foundation', 'PRE_FOUNDATION') THEN 'Pre_Foundation'\n",
    "            ELSE final_exam_category\n",
    "        END AS exam_2,\n",
    "        CASE \n",
    "            WHEN upgradedfrom IS NOT NULL THEN 'UPGRADE' \n",
    "            ELSE 'PRIMARY' \n",
    "        END AS order_type\n",
    "    FROM main\n",
    "    WHERE \n",
    "        isattribution = FALSE\n",
    "        AND isprimary = TRUE\n",
    "        AND issat = FALSE\n",
    "        AND isvidyapeeth = FALSE\n",
    "        AND ispathshala = FALSE\n",
    "        AND (organizationid IN ('5eb393ee95fab7468a79d189', '63b52963e72e8b00186c11f3'))\n",
    "        AND order_price > 0\n",
    "        AND (type = 'BATCH' OR type = 'COMBO_PACKAGE')\n",
    "        AND CAST(\n",
    "                date_add('minute', 330, CAST(order_time AS timestamp))\n",
    "            AS date\n",
    "        ) BETWEEN DATE '2025-02-28' AND DATE '2025-11-06'\n",
    ") m\n",
    "LEFT JOIN pw_store_order_cte s\n",
    "    ON m._id = s.ecom_id\n",
    "LEFT JOIN plans p\n",
    "    ON m.batchid = p.batchid)\n",
    "SELECT *,\n",
    "CASE \n",
    "    WHEN LOWER(plan) LIKE '%pro%' \n",
    "         AND Leader_FIN IN ('SANYAM', 'PRASHANT', 'MANISH', 'RAJAT') \n",
    "        THEN 'PRO'\n",
    "        \n",
    "    WHEN LOWER(plan) LIKE '%infinity%'\n",
    "        THEN 'INFINITY'\n",
    "        \n",
    "    WHEN plan = '' \n",
    "        THEN 'BATCH'\n",
    "        \n",
    "    ELSE 'BATCH'\n",
    "END AS type_2\n",
    "FROM filtration\n",
    "WHERE leader_fin = 'SANYAM'\n",
    "AND Exam_2 IN ('IIT-JEE','NEET','Foundation','CUET UG')\n",
    "\"\"\"\n",
    "\n",
    "# Date Settings\n",
    "DATE_MODE = 'yesterday'  # Options: 'today', 'yesterday', 'specific'\n",
    "SPECIFIC_DATE = '2025-11-04'  # Used only if DATE_MODE = 'specific'\n",
    "DAYS_BACK = 1  # Used only if DATE_MODE = 'yesterday'\n",
    "\n",
    "# ========================================================================================================\n",
    "# MAIN SCRIPT - NO NEED TO EDIT BELOW THIS LINE\n",
    "# ========================================================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä METABASE TO GOOGLE SHEETS - DATA FETCHER\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "from google.oauth2.service_account import Credentials\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Add Trino utilities path\n",
    "sys.path.append('/home/jovyan/shared/python_utils/')\n",
    "from python_utils_common import trino_prod\n",
    "\n",
    "print(\"\\n‚úÖ Configuration loaded\")\n",
    "print(f\"   Sheet: {WORKSHEET_NAME}\")\n",
    "print(f\"   Date Mode: {DATE_MODE}\")\n",
    "print(f\"   Query: {QUERY_NAME}\")\n",
    "print(f\"   Auto-delete old sheets: {AUTO_DELETE_OLD_SHEETS}\")\n",
    "print(f\"   Protect first sheet: {PROTECT_FIRST_SHEET}\")\n",
    "\n",
    "# ========================================================================================================\n",
    "# Calculate Query Date\n",
    "# ========================================================================================================\n",
    "\n",
    "if DATE_MODE == 'today':\n",
    "    query_date = datetime.now().date()\n",
    "elif DATE_MODE == 'yesterday':\n",
    "    query_date = (datetime.now() - timedelta(days=DAYS_BACK)).date()\n",
    "elif DATE_MODE == 'specific':\n",
    "    query_date = datetime.strptime(SPECIFIC_DATE, '%Y-%m-%d').date()\n",
    "else:\n",
    "    raise ValueError(f\"Invalid DATE_MODE: {DATE_MODE}\")\n",
    "\n",
    "print(f\"\\nüìÖ Query Date: {query_date}\")\n",
    "\n",
    "# ========================================================================================================\n",
    "# Execute Query and Fetch Data\n",
    "# ========================================================================================================\n",
    "\n",
    "formatted_query = SQL_QUERY.format(date=query_date)\n",
    "\n",
    "print(f\"\\nüîÑ Executing query: {QUERY_NAME}\")\n",
    "print(f\"   Date: {query_date}\")\n",
    "\n",
    "try:\n",
    "    start_time = time.time()\n",
    "    df = trino_prod(formatted_query)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n‚úÖ Query completed in {elapsed:.2f} seconds\")\n",
    "    print(f\"   Rows: {len(df)} | Columns: {len(df.columns)}\")\n",
    "    print(f\"\\nüìä Preview (first 3 rows):\")\n",
    "    display(df.head(3))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error executing query: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# ========================================================================================================\n",
    "# Upload to Google Sheets (LIGHTNING FAST MODE WITH SMART SPACE MANAGEMENT)\n",
    "# ========================================================================================================\n",
    "\n",
    "if len(df) == 0:\n",
    "    print(\"\\n‚ö†Ô∏è  No data to upload (query returned 0 rows)\")\n",
    "else:\n",
    "    print(f\"\\n‚ö° Uploading {len(df)} rows to Google Sheets...\")\n",
    "    upload_start = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Setup Google Sheets connection (cached credentials)\n",
    "        scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n",
    "        creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=scope)\n",
    "        client = gspread.authorize(creds)\n",
    "        \n",
    "        # Open spreadsheet\n",
    "        spreadsheet = client.open_by_key(SPREADSHEET_ID)\n",
    "        \n",
    "        # Get or create worksheet\n",
    "        try:\n",
    "            worksheet = spreadsheet.worksheet(WORKSHEET_NAME)\n",
    "            print(f\"   ‚úì Using existing worksheet: {WORKSHEET_NAME}\")\n",
    "        except gspread.exceptions.WorksheetNotFound:\n",
    "            # Create with minimal initial size\n",
    "            worksheet = spreadsheet.add_worksheet(title=WORKSHEET_NAME, rows=10, cols=5)\n",
    "            print(f\"   ‚úì Created new worksheet: {WORKSHEET_NAME}\")\n",
    "        \n",
    "        # Calculate required dimensions\n",
    "        metadata_rows = 5\n",
    "        required_rows = len(df) + metadata_rows + 1  # +1 for header\n",
    "        required_cols = len(df.columns)\n",
    "        required_cells = required_rows * required_cols\n",
    "        \n",
    "        print(f\"   Required: {required_rows:,} rows x {required_cols} cols = {required_cells:,} cells\")\n",
    "        \n",
    "        # Check current size\n",
    "        current_rows = worksheet.row_count\n",
    "        current_cols = worksheet.col_count\n",
    "        current_sheet_cells = current_rows * current_cols\n",
    "        \n",
    "        # Calculate total cells across all sheets\n",
    "        all_worksheets = spreadsheet.worksheets()\n",
    "        total_cells_used = sum(ws.row_count * ws.col_count for ws in all_worksheets)\n",
    "        cells_available = 10_000_000 - total_cells_used\n",
    "        cells_needed_for_resize = required_cells - current_sheet_cells\n",
    "        \n",
    "        print(f\"   Current spreadsheet: {total_cells_used:,} / 10,000,000 cells used\")\n",
    "        print(f\"   Available: {cells_available:,} cells\")\n",
    "        print(f\"   Need to add: {cells_needed_for_resize:,} cells\")\n",
    "        \n",
    "        # Free up space if needed\n",
    "        if cells_needed_for_resize > cells_available:\n",
    "            cells_to_free = cells_needed_for_resize - cells_available + 100_000  # 100k buffer\n",
    "            print(f\"\\n   ‚ö†Ô∏è  Insufficient space! Need to free {cells_to_free:,} cells...\")\n",
    "            \n",
    "            if not AUTO_DELETE_OLD_SHEETS:\n",
    "                print(\"\\n   ‚ùå AUTO_DELETE_OLD_SHEETS is set to False\")\n",
    "                print(\"   Options:\")\n",
    "                print(\"   1. Set AUTO_DELETE_OLD_SHEETS = True in configuration\")\n",
    "                print(\"   2. Manually delete old sheets from the spreadsheet\")\n",
    "                print(f\"   3. View spreadsheet: https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/edit\")\n",
    "                raise Exception(\"Insufficient space and auto-delete is disabled\")\n",
    "            \n",
    "            # Get all sheets sorted by size (largest first)\n",
    "            worksheet_sizes = []\n",
    "            for ws in all_worksheets:\n",
    "                ws_cells = ws.row_count * ws.col_count\n",
    "                ws_title = ws.title\n",
    "                \n",
    "                # Skip target worksheet\n",
    "                if ws_title == WORKSHEET_NAME:\n",
    "                    continue\n",
    "                \n",
    "                # Skip first sheet if protected\n",
    "                if PROTECT_FIRST_SHEET and ws.id == all_worksheets[0].id:\n",
    "                    continue\n",
    "                \n",
    "                worksheet_sizes.append((ws, ws_cells, ws_title))\n",
    "            \n",
    "            worksheet_sizes.sort(key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            # Calculate how many sheets we can delete\n",
    "            total_deletable_cells = sum(size for _, size, _ in worksheet_sizes)\n",
    "            \n",
    "            if not worksheet_sizes:\n",
    "                print(\"\\n   ‚ùå No deletable sheets found!\")\n",
    "                print(\"   Current sheets:\")\n",
    "                for ws in all_worksheets:\n",
    "                    protected = \" [PROTECTED]\" if (PROTECT_FIRST_SHEET and ws.id == all_worksheets[0].id) else \"\"\n",
    "                    target = \" [TARGET]\" if ws.title == WORKSHEET_NAME else \"\"\n",
    "                    print(f\"      - {ws.title} ({ws.row_count * ws.col_count:,} cells){protected}{target}\")\n",
    "                print(f\"\\n   Options:\")\n",
    "                print(f\"   1. Set PROTECT_FIRST_SHEET = False to allow deleting the first sheet\")\n",
    "                print(f\"   2. Manually delete old sheets\")\n",
    "                print(f\"   3. View spreadsheet: https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/edit\")\n",
    "                raise Exception(\"No deletable sheets available\")\n",
    "            \n",
    "            if total_deletable_cells < cells_to_free:\n",
    "                print(f\"\\n   ‚ö†Ô∏è  WARNING: Can only free {total_deletable_cells:,} cells, but need {cells_to_free:,}\")\n",
    "                print(f\"   This may still fail. Consider:\")\n",
    "                print(f\"   1. Setting PROTECT_FIRST_SHEET = False\")\n",
    "                print(f\"   2. Manually deleting more sheets\")\n",
    "                print(f\"   3. Creating a new spreadsheet\")\n",
    "                print(f\"\\n   Attempting to delete all available sheets anyway...\")\n",
    "            \n",
    "            cells_freed = 0\n",
    "            sheets_deleted = 0\n",
    "            \n",
    "            for ws, size, title in worksheet_sizes:\n",
    "                if cells_freed >= cells_to_free:\n",
    "                    break\n",
    "                \n",
    "                print(f\"   ‚úì Deleting '{title}' ({size:,} cells)\")\n",
    "                spreadsheet.del_worksheet(ws)\n",
    "                cells_freed += size\n",
    "                sheets_deleted += 1\n",
    "                time.sleep(0.5)  # Rate limiting\n",
    "            \n",
    "            print(f\"   ‚úì Freed {cells_freed:,} cells by deleting {sheets_deleted} sheet(s)\")\n",
    "            \n",
    "            # Update available cells\n",
    "            cells_available = cells_available + cells_freed\n",
    "            if cells_needed_for_resize > cells_available:\n",
    "                print(f\"\\n   ‚ö†Ô∏è  Still insufficient space after deleting all available sheets\")\n",
    "                print(f\"   Available: {cells_available:,} | Needed: {cells_needed_for_resize:,}\")\n",
    "                print(f\"   Set PROTECT_FIRST_SHEET = False or manually delete more sheets\")\n",
    "                raise Exception(\"Insufficient space even after deleting all available sheets\")\n",
    "        \n",
    "        # Dynamically resize ONLY if needed\n",
    "        needs_resize = False\n",
    "        new_rows = current_rows\n",
    "        new_cols = current_cols\n",
    "        \n",
    "        if current_rows < required_rows:\n",
    "            new_rows = required_rows\n",
    "            needs_resize = True\n",
    "        \n",
    "        if current_cols < required_cols:\n",
    "            new_cols = required_cols\n",
    "            needs_resize = True\n",
    "        \n",
    "        if needs_resize:\n",
    "            worksheet.resize(rows=new_rows, cols=new_cols)\n",
    "            print(f\"   ‚úì Resized to {new_rows:,} rows x {new_cols} cols = {new_rows * new_cols:,} cells\")\n",
    "        \n",
    "        # Clear existing data (FAST)\n",
    "        worksheet.clear()\n",
    "        \n",
    "        # Prepare metadata\n",
    "        metadata = [\n",
    "            [QUERY_NAME],\n",
    "            [f\"Date: {query_date}\"],\n",
    "            [f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"],\n",
    "            [f\"Records: {len(df)}\"],\n",
    "            []\n",
    "        ]\n",
    "        \n",
    "        # BATCH UPDATE - Update metadata in one call\n",
    "        metadata_range = f'A1:A{len(metadata)}'\n",
    "        worksheet.update(metadata_range, metadata, value_input_option='RAW')\n",
    "        \n",
    "        # Upload dataframe (FAST - single API call)\n",
    "        set_with_dataframe(\n",
    "            worksheet, \n",
    "            df, \n",
    "            row=len(metadata) + 1,\n",
    "            include_index=False,\n",
    "            include_column_header=True,\n",
    "            resize=False  # We already resized, no need to resize again\n",
    "        )\n",
    "        \n",
    "        # Format header (FAST - single API call)\n",
    "        header_row = len(metadata) + 1\n",
    "        worksheet.format(f'A{header_row}:{chr(65 + len(df.columns) - 1)}{header_row}', {\n",
    "            \"textFormat\": {\"bold\": True},\n",
    "            \"backgroundColor\": {\"red\": 0.2, \"green\": 0.5, \"blue\": 0.8}\n",
    "        })\n",
    "        \n",
    "        upload_time = time.time() - upload_start\n",
    "        print(f\"\\n‚úÖ Upload completed in {upload_time:.2f} seconds\")\n",
    "        print(f\"   Spreadsheet: https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/edit\")\n",
    "        print(f\"   Worksheet: {WORKSHEET_NAME}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error uploading to Google Sheets: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# ========================================================================================================\n",
    "# Summary\n",
    "# ========================================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìã EXECUTION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Query Name:    {QUERY_NAME}\")\n",
    "print(f\"Query Date:    {query_date}\")\n",
    "print(f\"Rows Fetched:  {len(df)}\")\n",
    "print(f\"Columns:       {len(df.columns)}\")\n",
    "print(f\"Sheet Tab:     {WORKSHEET_NAME}\")\n",
    "print(f\"Column Names:  {', '.join(df.columns.tolist())}\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nüéâ Process completed successfully!\")\n",
    "print(f\"View: https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/edit\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
